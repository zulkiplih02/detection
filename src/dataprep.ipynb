{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from shutil import copyfile\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '~/Development/Learning/cek/LicensePlate_CLAHE'\n",
    "image_links = 'train-images-boxable.csv'\n",
    "annot_box = 'train-annotations-bbox.csv'\n",
    "class_labels = 'class-descriptions-boxable.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/asdarmld/Development/Learning/cek/LicensePlate_CLAHEtrain-images-boxable.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/asdarmld/Development/Learning/cek/LicensePlate_CLAHE/src/dataprep.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/asdarmld/Development/Learning/cek/LicensePlate_CLAHE/src/dataprep.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_image_links \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(base_path\u001b[39m+\u001b[39;49mimage_links)\n",
      "File \u001b[0;32m~/Development/Learning/cek/LicensePlate_CLAHE/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Development/Learning/cek/LicensePlate_CLAHE/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Development/Learning/cek/LicensePlate_CLAHE/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Development/Learning/cek/LicensePlate_CLAHE/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Development/Learning/cek/LicensePlate_CLAHE/.venv/lib/python3.9/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/asdarmld/Development/Learning/cek/LicensePlate_CLAHEtrain-images-boxable.csv'"
     ]
    }
   ],
   "source": [
    "df_image_links = pd.read_csv(base_path+image_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annot_box = pd.read_csv(base_path+annot_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_labels = pd.read_csv(base_path+class_labels,header=None)\n",
    "df_class_labels.columns=['id','name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_org_img_with_boxes(image_name):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    image_name(string) = the actual file name '6b5bfa4e9b0e767c.jpg'\n",
    "    \n",
    "    Return:\n",
    "    One plot of the original image no bounding boxes, the other with bounding boxes.\n",
    "    \"\"\"\n",
    "    temp = df_image_links[df_image_links['image_name']==image_name]\n",
    "    img_url = temp['image_url'].values[0]\n",
    "    img_id = image_name[:16]\n",
    "    \n",
    "    img = io.imread(img_url)\n",
    "    \n",
    "    height, width, _ = img.shape\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Original Image')\n",
    "    plt.imshow(img)\n",
    "    boxes = df_annot_box[df_annot_box['ImageID']==img_id]\n",
    "    img_bbox = img.copy()\n",
    "    for index, row in boxes.iterrows():\n",
    "        xmin,xmax,ymin,ymax = row['XMin'],row['XMax'],row['YMin'],row['YMax']\n",
    "        xmin,xmax,ymin,ymax = int(xmin*width),int(xmax*width),int(ymin*height),int(ymax*height)\n",
    "        label_name = row['LabelName']\n",
    "        \n",
    "        temp_df = df_class_labels[df_class_labels['id']==label_name]\n",
    "        class_of_box = temp_df['name'].values[0]\n",
    "        \n",
    "        cv2.rectangle(img_bbox,(xmin,ymin),(xmax,ymax),(255,255,0),2)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img_bbox,class_of_box,(xmin,ymin-10), font, 1,(255,255,0),2)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Image with Bounding Box')\n",
    "    plt.imshow(img_bbox)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(which_class, num_rows,save=False,save_path ='~/Object-detection-using-Faster-RCNN/createddata/'):\n",
    "    \"\"\"Input: \n",
    "    which_class(str): one of 600 classes available in the dataset\n",
    "    num_rows(int): how many rows you want your csv to be could potentially be less than inputted if not that many in data\n",
    "    \n",
    "    Returns: \n",
    "    Df with num_rows randomly chosen number of rows\n",
    "    if save==True: saves it as a csv in save_path + (which_class)_1000.csv\n",
    "    \n",
    "    \"\"\"\n",
    "    class_id = df_class_labels[df_class_labels['name']==which_class].values[0][0] #collect the class_id value \n",
    "    num_total_pics = df_annot_box[df_annot_box['LabelName']==class_id] #select all the annotation boxes with that id value\n",
    "    print('Total amount of {} in data'.format(which_class))\n",
    "    print(len(num_total_pics))\n",
    "    \n",
    "    print('Number of unique pictures featuring atleast one of {}'.format(which_class))\n",
    "    num_unique_pics_of_class = np.unique(num_total_pics['ImageID']) #remove duplicate images from the df, \n",
    "    #such as smooshing down a picture that has 2 birds to one value\n",
    "    print(len(num_unique_pics_of_class))\n",
    "    random_rows = np.random.choice(num_unique_pics_of_class,num_rows,replace=False)#randomly choose Num_rows\n",
    "    array_append_jpg = [df_image_links[df_image_links['image_name']==name+'.jpg'] for name in random_rows]\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(array_append_jpg)):\n",
    "        df = df.append(array_append_jpg[i], ignore_index = True)\n",
    "    if save:\n",
    "        df.to_csv(save_path + '{}_{}.csv'.format(which_class,num_rows))\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(csv_file_path, save_file_path, type_of_class):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    csv_file_path(string) = path to where you saved the csv generated from create_csv\n",
    "    save_file_path(string) = path to where you want to save all of the images\n",
    "    type_of_class(string) = whichever class('Person', 'Bird', etc...)\n",
    "    \n",
    "    Returns: None\n",
    "    \n",
    "    Generates: A new folder with the name of type_of_class with all the images downloaded inside of it\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    if len(df.columns) >=3:\n",
    "        df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "    urls = df['image_url'].values\n",
    "    directory = save_file_path + type_of_class\n",
    "    os.mkdir(directory)\n",
    "    for url in urls:\n",
    "        img = io.imread(url)\n",
    "        file_name=url[-20:]\n",
    "        io.imsave(directory+'/'+file_name, img)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../createddata/train/'\n",
    "test_path = '../createddata/test/'\n",
    "# os.mkdir(train_path)\n",
    "# os.mkdir(test_path)\n",
    "def split_train_test(file_path_to_imgs, percentage_split=.8, save_path_train = '../createddata/train/',save_path_test = '../createddata/test/'):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    file_path_to_imgs = file path to the image directory where all the downloaded images from download_images() are saved\n",
    "    percentage_split(int between 0-1) = Default at .8 The percentage you want to be train images, remaining percent is test\n",
    "    save_path_train = file path where you want to save the train images\n",
    "    save_path_test = file path where you want to save the test images\n",
    "    \n",
    "    RETURNS: None\n",
    "    \n",
    "    Generates:\n",
    "    Copied images into specificed train and test directorys\n",
    "    \"\"\"\n",
    "    imgs = os.listdir(file_path_to_imgs)\n",
    "    imgs = [f for f in imgs if not f.startswith('.')]\n",
    "    random.seed(1)\n",
    "    random.shuffle(imgs)\n",
    "    num_of_train_imgs = int(len(imgs)*percentage_split)\n",
    "    num_of_test_imgs =len(imgs)-int(len(imgs)*(1-percentage_split))\n",
    "    train_imgs = imgs[:num_of_train_imgs]\n",
    "    test_imgs = imgs[num_of_test_imgs:]\n",
    "    for val in train_imgs:\n",
    "        img_loc = file_path_to_imgs + val\n",
    "        save_loc = save_path_train+val\n",
    "        copyfile(img_loc, save_loc)\n",
    "    for val in test_imgs:\n",
    "        img_loc = file_path_to_imgs + val\n",
    "        save_loc = save_path_test+val\n",
    "        copyfile(img_loc, save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_out_of_image_folders(path,names_of_classes=[],save=False, type_of_data='train'):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "    path = path to where you just stored your train or test pictures\n",
    "    names_of_classes = A list with the classes you've chosen for your data ('Bird','Person,'Traffic light'...etc)\n",
    "    save = True save a csv file you can load in with this information\n",
    "    type_of_data = actually just used as a variable to name your saved csv \n",
    "    ex:\n",
    "    if type_of_data = 'train' file will save as 'train_df.csv'\n",
    "    \n",
    "    Returns:\n",
    "    dataframe with format [FileName, XMIN, XMax, YMin, Ymax, ClassName] for each bounding box\n",
    "    \n",
    "    \"\"\"\n",
    "    class_id = []\n",
    "    for val in names_of_classes:\n",
    "        class_id.append(df_class_labels[df_class_labels['name']==val].values[0][0])\n",
    "    df = pd.DataFrame(columns=['FileName', 'XMin', 'XMax', 'YMin', 'YMax', 'ClassName'])\n",
    "    train_imgs = os.listdir(path)\n",
    "    train_imgs = [name for name in train_imgs if not name.startswith('.')]\n",
    "    for i in range(len(train_imgs)):\n",
    "        sys.stdout.write('Parse train_imgs ' + str(i) + '; Number of boxes: ' + str(len(df)) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        img_name = train_imgs[i]\n",
    "        img_id = img_name[0:16]\n",
    "        tmp_df = df_annot_box[df_annot_box['ImageID']==img_id]\n",
    "        for index,row in tmp_df.iterrows():\n",
    "            labelname=row['LabelName']\n",
    "            for val in range(len(names_of_classes)):\n",
    "                if labelname == class_id[val]:\n",
    "                    df = df.append({'FileName': img_name, \n",
    "                                            'XMin': row['XMin'], \n",
    "                                            'XMax': row['XMax'], \n",
    "                                            'YMin': row['YMin'], \n",
    "                                            'YMax': row['YMax'], \n",
    "                                            'ClassName': names_of_classes[val]}, \n",
    "                                           ignore_index=True)\n",
    "    if save:\n",
    "        df.to_csv('../createddata/{}_df.csv'.format(type_of_data))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use case for preparing data from the google AI dataset\n",
    "base_path = '~/Object-detection-using-Faster-RCNN/createddata/'\n",
    "create_csv('Person',num_rows=2500, save=True, save_path = base_path)\n",
    "download_images(base_path + 'Person_1000.csv',base_path +'/images/', 'Person')\n",
    "split_train_test(base_path+'/images/', percentage_splot=.8,save_path_train='../createddata/train/',save_path_test= '../createddata/test')\n",
    "train_df = create_df_out_of_image_folders('../createddata/train/',names_of_classes=['Person'], save =True, type_of_data='train')\n",
    "test_df = create_df_out_of_image_folders('../createddata/test/',names_of_classes=['Person'], save =True, type_of_data='test')\n",
    "\n",
    "#Example of where to call in the csvs generated from 'create_df_out_of_image_folders' if working with them later\n",
    "# train_df = pd.read_csv('../createddata/train_df.csv')\n",
    "# train_df.drop('Unnamed: 0',inplace=True,axis=1)\n",
    "\n",
    "# test_df = pd.read_csv('../createddata/test_df.csv')\n",
    "# test_df.drop('Unnamed: 0',inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training\n",
    "\n",
    "f= open('../createddata' + \"/train_annotation.txt\",\"w+\")\n",
    "for idx, row in train_df.iterrows():\n",
    "#     sys.stdout.write(str(idx) + '\\r')\n",
    "#     sys.stdout.flush()\n",
    "    img = cv2.imread(('../createddata' + '/train/' + row['FileName']))\n",
    "    plt.imshow(img)\n",
    "    height, width = img.shape[:2]\n",
    "    x1 = int(row['XMin'] * width)\n",
    "    x2 = int(row['XMax'] * width)\n",
    "    y1 = int(row['YMin'] * height)\n",
    "    y2 = int(row['YMax'] * height)\n",
    "    \n",
    "    fileName = '/home/ubuntu/Object-detection-using-Faster-RCNN/createddata/train/' +row['FileName']\n",
    "    className = row['ClassName']\n",
    "    other_name = '/home/ubuntu/Object-detection-using-Faster-RCNN/createddata/train/' +row['FileName']\n",
    "    f.write(other_name + ',' + str(x1) + ',' + str(y1) + ',' + str(x2) + ',' + str(y2) + ',' + className + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f= open('../createddata' + \"/test_annotation.txt\",\"w+\")\n",
    "for idx, row in test_df.iterrows():\n",
    "#     sys.stdout.write(str(idx) + '\\r')\n",
    "#     sys.stdout.flush()\n",
    "    img = cv2.imread(('../createddata' + '/test/' + row['FileName']))\n",
    "    height, width = img.shape[:2]\n",
    "    x1 = int(row['XMin'] * width)\n",
    "    x2 = int(row['XMax'] * width)\n",
    "    y1 = int(row['YMin'] * height)\n",
    "    y2 = int(row['YMax'] * height)\n",
    "    \n",
    "    fileName = '/Users/davidheller/Object-detection-using-Faster-RCNN/createddata/test/' +row['FileName']\n",
    "    other_name = '/home/ubuntu/Object-detection-using-Faster-RCNN/createddata/test/' +row['FileName']\n",
    "    className = row['ClassName']\n",
    "    f.write(other_name + ',' + str(x1) + ',' + str(y1) + ',' + str(x2) + ',' + str(y2) + ',' + className + '\\n')\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
