{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-23 17:03:14.931312: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from shutil import copyfile\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../createmetadata/'\n",
    "image_links = '../data/train-images-boxable.csv'\n",
    "annot_box = '../data/train-annotations-bbox.csv'\n",
    "class_labels = '../data/class-descriptions-boxable.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_links = pd.read_csv(image_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annot_box = pd.read_csv(annot_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_labels = pd.read_csv(class_labels,header=None)\n",
    "df_class_labels.columns=['id','name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_org_img_with_boxes(image_name):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    image_name(string) = the actual file name '6b5bfa4e9b0e767c.jpg'\n",
    "    \n",
    "    Return:\n",
    "    One plot of the original image no bounding boxes, the other with bounding boxes.\n",
    "    \"\"\"\n",
    "    temp = df_image_links[df_image_links['image_name']==image_name]\n",
    "    img_url = temp['image_url'].values[0]\n",
    "    img_id = image_name[:16]\n",
    "    \n",
    "    img = io.imread(img_url)\n",
    "    \n",
    "    height, width, _ = img.shape\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Original Image')\n",
    "    plt.imshow(img)\n",
    "    boxes = df_annot_box[df_annot_box['ImageID']==img_id]\n",
    "    img_bbox = img.copy()\n",
    "    for index, row in boxes.iterrows():\n",
    "        xmin,xmax,ymin,ymax = row['XMin'],row['XMax'],row['YMin'],row['YMax']\n",
    "        xmin,xmax,ymin,ymax = int(xmin*width),int(xmax*width),int(ymin*height),int(ymax*height)\n",
    "        label_name = row['LabelName']\n",
    "        \n",
    "        temp_df = df_class_labels[df_class_labels['id']==label_name]\n",
    "        class_of_box = temp_df['name'].values[0]\n",
    "        \n",
    "        cv2.rectangle(img_bbox,(xmin,ymin),(xmax,ymax),(255,255,0),2)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img_bbox,class_of_box,(xmin,ymin-10), font, 1,(255,255,0),2)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Image with Bounding Box')\n",
    "    plt.imshow(img_bbox)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(which_class, num_rows,save=False,save_path ='../createmetadata/'):\n",
    "    \"\"\"Input: \n",
    "    which_class(str): one of 600 classes available in the dataset\n",
    "    num_rows(int): how many rows you want your csv to be could potentially be less than inputted if not that many in data\n",
    "    \n",
    "    Returns: \n",
    "    Df with num_rows randomly chosen number of rows\n",
    "    if save==True: saves it as a csv in save_path + (which_class)_1000.csv\n",
    "    \n",
    "    \"\"\"\n",
    "    class_id = df_class_labels[df_class_labels['name']==which_class].values[0][0] #collect the class_id value \n",
    "    num_total_pics = df_annot_box[df_annot_box['LabelName']==class_id] #select all the annotation boxes with that id value\n",
    "    print('Total amount of {} in data'.format(which_class))\n",
    "    print(len(num_total_pics))\n",
    "    \n",
    "    print('Number of unique pictures featuring atleast one of {}'.format(which_class))\n",
    "    num_unique_pics_of_class = np.unique(num_total_pics['ImageID']) #remove duplicate images from the df, \n",
    "    #such as smooshing down a picture that has 2 birds to one value\n",
    "    print(len(num_unique_pics_of_class))\n",
    "    random_rows = np.random.choice(num_unique_pics_of_class,num_rows,replace=False)#randomly choose Num_rows\n",
    "    array_append_jpg = [df_image_links[df_image_links['image_name']==name+'.jpg'] for name in random_rows]\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(array_append_jpg)):\n",
    "        df = df.append(array_append_jpg[i], ignore_index = True)\n",
    "    if save:\n",
    "        df.to_csv(save_path + '{}_{}.csv'.format(which_class,num_rows))\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(csv_file_path, save_file_path, type_of_class):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    csv_file_path(string) = path to where you saved the csv generated from create_csv\n",
    "    save_file_path(string) = path to where you want to save all of the images\n",
    "    type_of_class(string) = whichever class('Person', 'Bird', etc...)\n",
    "    \n",
    "    Returns: None\n",
    "    \n",
    "    Generates: A new folder with the name of type_of_class with all the images downloaded inside of it\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    if len(df.columns) >=3:\n",
    "        df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "    urls = df['image_url'].values\n",
    "    directory = save_file_path + type_of_class\n",
    "    os.mkdir(directory)\n",
    "    for url in urls:\n",
    "        img = io.imread(url)\n",
    "        file_name=url[-20:]\n",
    "        io.imsave(directory+'/'+file_name, img)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../createddata/train/'\n",
    "test_path = '../createddata/test/'\n",
    "# os.mkdir(train_path)\n",
    "# os.mkdir(test_path)\n",
    "def split_train_test(file_path_to_imgs, percentage_split=.8, save_path_train = '../createddata/train/',save_path_test = '../createddata/test/'):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    file_path_to_imgs = file path to the image directory where all the downloaded images from download_images() are saved\n",
    "    percentage_split(int between 0-1) = Default at .8 The percentage you want to be train images, remaining percent is test\n",
    "    save_path_train = file path where you want to save the train images\n",
    "    save_path_test = file path where you want to save the test images\n",
    "    \n",
    "    RETURNS: None\n",
    "    \n",
    "    Generates:\n",
    "    Copied images into specificed train and test directorys\n",
    "    \"\"\"\n",
    "    imgs = os.listdir(file_path_to_imgs)\n",
    "    imgs = [f for f in imgs if not f.startswith('.')]\n",
    "    random.seed(1)\n",
    "    random.shuffle(imgs)\n",
    "    num_of_train_imgs = int(len(imgs)*percentage_split)\n",
    "    num_of_test_imgs =len(imgs)-int(len(imgs)*(1-percentage_split))\n",
    "    train_imgs = imgs[:num_of_train_imgs]\n",
    "    test_imgs = imgs[num_of_test_imgs:]\n",
    "    for val in train_imgs:\n",
    "        img_loc = file_path_to_imgs + val\n",
    "        save_loc = save_path_train+val\n",
    "        copyfile(img_loc, save_loc)\n",
    "    for val in test_imgs:\n",
    "        img_loc = file_path_to_imgs + val\n",
    "        save_loc = save_path_test+val\n",
    "        copyfile(img_loc, save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_out_of_image_folders(path,names_of_classes=[],save=False, type_of_data='train'):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "    path = path to where you just stored your train or test pictures\n",
    "    names_of_classes = A list with the classes you've chosen for your data ('Bird','Person,'Traffic light'...etc)\n",
    "    save = True save a csv file you can load in with this information\n",
    "    type_of_data = actually just used as a variable to name your saved csv \n",
    "    ex:\n",
    "    if type_of_data = 'train' file will save as 'train_df.csv'\n",
    "    \n",
    "    Returns:\n",
    "    dataframe with format [FileName, XMIN, XMax, YMin, Ymax, ClassName] for each bounding box\n",
    "    \n",
    "    \"\"\"\n",
    "    class_id = []\n",
    "    for val in names_of_classes:\n",
    "        class_id.append(df_class_labels[df_class_labels['name']==val].values[0][0])\n",
    "    df = pd.DataFrame(columns=['FileName', 'XMin', 'XMax', 'YMin', 'YMax', 'ClassName'])\n",
    "    train_imgs = os.listdir(path)\n",
    "    train_imgs = [name for name in train_imgs if not name.startswith('.')]\n",
    "    for i in range(len(train_imgs)):\n",
    "        sys.stdout.write('Parse train_imgs ' + str(i) + '; Number of boxes: ' + str(len(df)) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        img_name = train_imgs[i]\n",
    "        img_id = img_name[0:16]\n",
    "        tmp_df = df_annot_box[df_annot_box['ImageID']==img_id]\n",
    "        for index,row in tmp_df.iterrows():\n",
    "            labelname=row['LabelName']\n",
    "            for val in range(len(names_of_classes)):\n",
    "                if labelname == class_id[val]:\n",
    "                    df = df.append({'FileName': img_name, \n",
    "                                            'XMin': row['XMin'], \n",
    "                                            'XMax': row['XMax'], \n",
    "                                            'YMin': row['YMin'], \n",
    "                                            'YMax': row['YMax'], \n",
    "                                            'ClassName': names_of_classes[val]}, \n",
    "                                           ignore_index=True)\n",
    "    if save:\n",
    "        df.to_csv('../createddata/{}_df.csv'.format(type_of_data))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of Person in data\n",
      "1034721\n",
      "Number of unique pictures featuring atleast one of Person\n",
      "248384\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'image_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Use case for preparing data from the google AI dataset\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m base_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../createmetadata\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m create_csv(\u001b[39m'\u001b[39;49m\u001b[39mPerson\u001b[39;49m\u001b[39m'\u001b[39;49m,num_rows\u001b[39m=\u001b[39;49m\u001b[39m2500\u001b[39;49m, save\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, save_path \u001b[39m=\u001b[39;49m base_path)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m download_images(base_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mPerson_1000.csv\u001b[39m\u001b[39m'\u001b[39m,base_path \u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/images/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPerson\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m split_train_test(base_path\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/images/\u001b[39m\u001b[39m'\u001b[39m, percentage_splot\u001b[39m=\u001b[39m\u001b[39m.8\u001b[39m,save_path_train\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../createddata/train/\u001b[39m\u001b[39m'\u001b[39m,save_path_test\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../createddata/test\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(num_unique_pics_of_class))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m random_rows \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(num_unique_pics_of_class,num_rows,replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m#randomly choose Num_rows\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m array_append_jpg \u001b[39m=\u001b[39m [df_image_links[df_image_links[\u001b[39m'\u001b[39;49m\u001b[39mimage_name\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m==\u001b[39;49mname\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.jpg\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m name \u001b[39min\u001b[39;49;00m random_rows]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(array_append_jpg)):\n",
      "\u001b[1;32m/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(num_unique_pics_of_class))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m random_rows \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(num_unique_pics_of_class,num_rows,replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m#randomly choose Num_rows\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m array_append_jpg \u001b[39m=\u001b[39m [df_image_links[df_image_links[\u001b[39m'\u001b[39;49m\u001b[39mimage_name\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m==\u001b[39mname\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m random_rows]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(array_append_jpg)):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image_name'"
     ]
    }
   ],
   "source": [
    "#Use case for preparing data from the google AI dataset\n",
    "base_path = '../createmetadata'\n",
    "create_csv('Person',num_rows=2500, save=True, save_path = base_path)\n",
    "download_images(base_path + 'Person_1000.csv',base_path +'/images/', 'Person')\n",
    "split_train_test(base_path+'/images/', percentage_splot=.8,save_path_train='../createddata/train/',save_path_test= '../createddata/test')\n",
    "train_df = create_df_out_of_image_folders('../createddata/train/',names_of_classes=['Person'], save =True, type_of_data='train')\n",
    "test_df = create_df_out_of_image_folders('../createddata/test/',names_of_classes=['Person'], save =True, type_of_data='test')\n",
    "\n",
    "#Example of where to call in the csvs generated from 'create_df_out_of_image_folders' if working with them later\n",
    "# train_df = pd.read_csv('../createddata/train_df.csv')\n",
    "# train_df.drop('Unnamed: 0',inplace=True,axis=1)\n",
    "\n",
    "# test_df = pd.read_csv('../createddata/test_df.csv')\n",
    "# test_df.drop('Unnamed: 0',inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training\n",
    "\n",
    "f= open('../createddata' + \"/train_annotation.txt\",\"w+\")\n",
    "for idx, row in train_df.iterrows():\n",
    "#     sys.stdout.write(str(idx) + '\\r')\n",
    "#     sys.stdout.flush()\n",
    "    img = cv2.imread(('../createddata' + '/train/' + row['FileName']))\n",
    "    plt.imshow(img)\n",
    "    height, width = img.shape[:2]\n",
    "    x1 = int(row['XMin'] * width)\n",
    "    x2 = int(row['XMax'] * width)\n",
    "    y1 = int(row['YMin'] * height)\n",
    "    y2 = int(row['YMax'] * height)\n",
    "    \n",
    "    fileName = '/home/ubuntu/Object-detection-using-Faster-RCNN/createddata/train/' +row['FileName']\n",
    "    className = row['ClassName']\n",
    "    other_name = '/home/ubuntu/Object-detection-using-Faster-RCNN/createddata/train/' +row['FileName']\n",
    "    f.write(other_name + ',' + str(x1) + ',' + str(y1) + ',' + str(x2) + ',' + str(y2) + ',' + className + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../createddata/test_annotation.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m f\u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m../createddata\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/test_annotation.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mw+\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, row \u001b[39min\u001b[39;00m test_df\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#     sys.stdout.write(str(idx) + '\\r')\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#     sys.stdout.flush()\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/Documents/KULIAH/TESIS/DILLA/thesis-dilla/src/dataprep.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread((\u001b[39m'\u001b[39m\u001b[39m../createddata\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/test/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mFileName\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../createddata/test_annotation.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "f= open('../createddata' + \"/test_annotation.txt\",\"w+\")\n",
    "for idx, row in test_df.iterrows():\n",
    "#     sys.stdout.write(str(idx) + '\\r')\n",
    "#     sys.stdout.flush()\n",
    "    img = cv2.imread(('../createddata' + '/test/' + row['FileName']))\n",
    "    height, width = img.shape[:2]\n",
    "    x1 = int(row['XMin'] * width)\n",
    "    x2 = int(row['XMax'] * width)\n",
    "    y1 = int(row['YMin'] * height)\n",
    "    y2 = int(row['YMax'] * height)\n",
    "    \n",
    "    fileName = '/Users/davidheller/Object-detection-using-Faster-RCNN/createddata/test/' +row['FileName']\n",
    "    other_name = '/home/ubuntu/Object-detection-using-Faster-RCNN/createddata/test/' +row['FileName']\n",
    "    className = row['ClassName']\n",
    "    f.write(other_name + ',' + str(x1) + ',' + str(y1) + ',' + str(x2) + ',' + str(y2) + ',' + className + '\\n')\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
